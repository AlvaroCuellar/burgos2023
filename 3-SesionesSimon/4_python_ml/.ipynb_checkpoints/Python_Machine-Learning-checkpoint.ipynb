{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0942cc-3c41-49a3-83f8-ced9cdc66baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the needed libraries\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import collections\n",
    "import re\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut,  GridSearchCV, RandomizedSearchCV, cross_val_predict, cross_val_score, cross_validate, KFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, classification_report, make_scorer, fbeta_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer, accuracy_score, fbeta_score, recall_score, precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#General\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08443a4-6899-492a-a6b9-6a1f7b8b7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def largeformat(data, column):\n",
    "    \"\"\"\n",
    "    Reshapes a pandas DataFrame from long to wide format, where each unique value in the specified column becomes a new column,\n",
    "    and the values in the 'Count' column become the values of the new columns. The resulting DataFrame has one row per unique value\n",
    "    in the 'Title' column, with the 'Author' and 'Title' columns repeated for each row. Any missing values are filled with 0.\n",
    "\n",
    "    Args:\n",
    "    data (pandas.DataFrame): The input DataFrame to reshape.\n",
    "    column (str): The column name to use for the new columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The reshaped DataFrame, in wide format.\n",
    "    \"\"\"\n",
    "    variables = list(pd.unique(data[column]))\n",
    "    dflarge = pd.DataFrame(columns=['Author', 'Title'] + variables)\n",
    "    plays = list(pd.unique(data['Title']))\n",
    "    for play in plays:\n",
    "        subset= data.loc[data['Title'] == play]\n",
    "        aux = {'Author': [subset['Author'].values[0]], 'Title': [play]}\n",
    "        for variable in variables:\n",
    "            if len(subset.loc[subset[column] == variable]) < 1:\n",
    "                aux[variable] = [0]\n",
    "            else:\n",
    "                aux[variable] = subset.loc[subset[column] ==\n",
    "                                                variable]['Count'].values\n",
    "        aux = pd.DataFrame(aux).reset_index(drop=True)\n",
    "        dflarge = pd.concat([dflarge, aux], ignore_index=True)\n",
    "    return dflarge.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec477c47-bec9-4600-8aef-835825ebcc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recount(data, column):\n",
    "    \"\"\"\n",
    "    Counts the number of occurrences of each unique value in a specified column of a pandas DataFrame, for each play in the \n",
    "    DataFrame. The resulting DataFrame includes the total count and relative count (count/nVerses) for each unique value of \n",
    "    the specified column, as well as the total number of verses in each play.\n",
    "\n",
    "    Args:\n",
    "    - data (pandas DataFrame): The input DataFrame to be analyzed.\n",
    "    - column (str): The name of the column to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    - total (pandas DataFrame): A DataFrame with the following columns:\n",
    "        - Author (str): The author of the play.\n",
    "        - Title (str): The title of the play.\n",
    "        - column (str): The unique value of the column for which counts were computed.\n",
    "        - Count (int): The total number of occurrences of the unique value in the play.\n",
    "        - RelCount (float): The relative frequency of the unique value in the play (Count/nVerses).\n",
    "        - nVerses (int): The total number of verses in the play.\n",
    "    \"\"\"\n",
    "\n",
    "    data = data[['Author', 'Title', column]]\n",
    "    plays = list(pd.unique(data['Title']))\n",
    "    total = pd.DataFrame(columns=['Author', 'Title', column, 'Count', 'RelCount', 'nVerses'])\n",
    "    for play in plays:\n",
    "        subset= data.loc[data['Title'] == play]\n",
    "        subset.loc[:,('nVerses')] = len(subset)\n",
    "        values = list(pd.unique(subset[column]))\n",
    "        for value in values:\n",
    "            subset.loc[subset[column] == value,\n",
    "                            'Count'] = len(subset.loc[subset[column] == value])\n",
    "            subset.loc[:,('RelCount')] = subset['Count']/subset['nVerses']\n",
    "        total = pd.concat([total, subset])\n",
    "    total.drop_duplicates(subset=['Title', column], inplace=True)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a6845-08e7-4e9a-8da1-1657b7c09097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nice_scores(y_test, y_predictions_dict):\n",
    "    \"\"\"\n",
    "    Calculate and return a Pandas DataFrame containing evaluation scores for the given models.\n",
    "\n",
    "    Args:\n",
    "    y_test (array-like): The true labels for the training data.\n",
    "    y_predictions_dict (dict): A dictionary of model names as keys and their predicted labels as values.\n",
    "\n",
    "    Returns:\n",
    "    A Pandas DataFrame containing the following columns:\n",
    "        - 'FBeta': The F-beta score with beta=0.5.\n",
    "        - 'Accuracy': The accuracy score.\n",
    "        - 'Recall': The recall score.\n",
    "        - 'Precision': The precision score.\n",
    "    The rows of the DataFrame correspond to the model names in the input dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame(columns=['FBeta', 'Accuracy', 'Recall', 'Precision'])\n",
    "\n",
    "    for model_name, predictions in y_predictions_dict.items():\n",
    "        fbeta = round(fbeta_score(y_test, predictions, beta=0.5), 3)\n",
    "        accuracy = round(accuracy_score(y_test, predictions), 3)\n",
    "        recall = round(recall_score(y_test, predictions), 3)\n",
    "        precision = round(precision_score(y_test, predictions), 3)\n",
    "        \n",
    "        df.loc[model_name] = [fbeta, accuracy, recall, precision]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a837ec-7093-46be-b9b1-470270c98269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo el archivo de entrada\n",
    "entry = 'corpus.csv'\n",
    "df = pd.read_csv(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dec403-3b15-43e5-9681-c31103a08a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have a lot of authors in this dataframe but actually just two of them have a similar weight.\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Set the font size\n",
    "mpl.rcParams['font.size'] = 12\n",
    "\n",
    "plt.figure(figsize=(26,22))\n",
    "df.groupby('Author')['Title'].nunique().plot(kind='pie', legend =True)\n",
    "plt.legend(bbox_to_anchor=(1.02, 1.02), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869a21d-d218-4e92-95bf-c099c0083114",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(26,12))\n",
    "\n",
    "ax = sns.countplot(data=df, x='Author')\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "ax.set_title(\"Number of Verses per Author\", fontsize=22)\n",
    "ax.set_xlabel(\"Authors\", fontsize=18)\n",
    "ax.set_ylabel(\"Vers Count\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f3cbe-57a2-4f55-b6f1-f495ea5c865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage of authors in relation to the whole dataframe\n",
    "\n",
    "author = df.groupby('Author').size() / len(df) *100\n",
    "plt.title('Percentage of playwrights in the dataframe')\n",
    "author.sort_values(ascending = True).plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7dd38-aa40-4db2-bc9b-787496c66fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's limit the data to the 65 most frequent rhythms\n",
    "#From previous works we know that 65 rhythms is a good number to start with.\n",
    "\n",
    "nritmos = 65\n",
    "\n",
    "frecuentes = df['Rhythm'].value_counts().head(65).index.tolist()\n",
    "dfg = df[df['Rhythm'].isin(frecuentes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e167bf25-ead5-4e21-b71e-67abf1e8eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because of the imbalance in the authors column we will convert the dataset into a binary one.\n",
    "#We want to know whether Calderón's rhythm is characteristic. All non-Calderonian plays are therefore converted to \"No-Calderón\".\n",
    "\n",
    "no_author = 'No Calderón'\n",
    "author = 'Calderón'\n",
    "candidatos = [author, no_author]\n",
    "\n",
    "\n",
    "dfg.loc[dfg[\"Author\"] != author, \"Author\"] = no_author\n",
    "\n",
    "#Some models need numnbers as target value, we replace Calderón and No Calderon with 1 and 0.\n",
    "dfg['Author'] = dfg['Author'].replace({'Calderón' : 1, 'No Calderón' : 0 })\n",
    "dfg.head()\n",
    "\n",
    "df = dfg.copy()\n",
    "df.Author.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb84e0df-0ad2-419a-8bc0-b23ec9ec5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the above functions we convert the dataframe into a dataset with columns for each rhythm.\n",
    "\n",
    "dfcount = recount(dfg, 'Rhythm')\n",
    "dfcount.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af7a57-a532-448d-8cde-8de330ba54d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflarge = largeformat(dfcount, 'Rhythm')\n",
    "dflarge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6353d2a-b8e8-4a86-a32f-ac2cf80f9765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the target variable \n",
    "Y = dflarge['Author']\n",
    "X = dflarge.drop(['Author', 'Title'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6330020-7487-4279-960a-ebd8da965223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = RSEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd62fb-7f7e-497e-8ed1-4ec6022e6164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling, the values differ quite much.\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54adf7cf-298b-47d2-9074-fa28f6fde460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try out several models\n",
    "clf_dt =  DecisionTreeClassifier(random_state=RSEED)\n",
    "clf_rf = RandomForestClassifier(random_state=RSEED)\n",
    "clf_xg = XGBClassifier(seed=RSEED)\n",
    "clf_ada = AdaBoostClassifier(random_state=RSEED)\n",
    "clf_lr = LogisticRegression(random_state=RSEED)     \n",
    "clf_sv = SVC(random_state=RSEED)\n",
    "clf_knn =  KNeighborsClassifier()   \n",
    "#clf_mnb =MultinomialNB()\n",
    "clf_g = GaussianNB()\n",
    "\n",
    "#Let's store the variantes in a list so we can loop through them\n",
    "list_of_models = [clf_dt, clf_rf, clf_xg, clf_ada, clf_ada, clf_lr, clf_sv, clf_knn, clf_g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ec922-6b6b-4af9-a01a-8cb9c4ea7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ytest_dict = {}\n",
    "fitted_models_dict = {}\n",
    "for model in list_of_models:\n",
    "    start_time = time.time()\n",
    "    model_name = type(model).__name__\n",
    "    fitted_models_dict[model_name] = model.fit(X_train, y_train)\n",
    "    pred_ytest_dict[model_name] = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    print(f\"{model_name} - Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69bb4cf-dcda-47d9-b659-ebca5f3044e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(nice_scores(y_test, pred_ytest_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86658d94-dbe7-4245-994a-be9ac0d89c28",
   "metadata": {},
   "source": [
    "# Beispiel für ein einziges Modell (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765bd577-8590-4ca4-a13f-e68dbd07781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbe26f-625e-467e-a4ed-4d0ca6b02453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = clf_sv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fedc22-741b-4bdc-94d0-a1ec74c3bd6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "precision = round(precision_score(y_test, y_pred), 3)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba5db3-59ba-4002-9c11-ccf04d2d777b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Define names for the four categories\n",
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "\n",
    "# Count the number for each category\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "\n",
    "# Define labels with both category names and counts\n",
    "labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names, group_counts)]\n",
    "\n",
    "# Convert labels into a matrix matching the confusion matrix\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "# Create a new figure with a specified size (width, height)\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Create a heatmap with labels and larger font size\n",
    "sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', annot_kws={\"size\": 14})\n",
    "\n",
    "\n",
    "plt.xlabel('Predicted', fontsize = 14)\n",
    "plt.ylabel('Actual', fontsize = 14)\n",
    "plt.title('Confusion Matrix', fontsize = 18)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
